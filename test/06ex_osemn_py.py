# -*- coding: utf-8 -*-
"""06ex_OSEMN.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16bhIYNYdh5CyULwakJ_D_lxyNAr5pZRd
"""

import pandas as pd
import numpy as np

import random
import json
import pandas as pd

#EX1


list = []
for i in range(0, 40):
    num = random.randint(0, 10)
    list.append(num)
with open('data_int.txt', 'w') as file:
    file.write('\n'.join(str(number) for number in list))

!cat data_int.txt

matrix = np.random.rand(5, 5)
fl = np.matrix(matrix)
with open('data_float.txt', 'w') as file:
    for row in fl:
        np.savetxt(file, row)

!cat data_float.txt

import csv

with open('data_float.txt', 'r') as file:
    load = (line.strip() for line in file)
    lines = (line.split(",") for line in load if line)
    with open('data_float.csv', 'w') as out_file:
        writer = csv.writer(out_file)
        writer.writerow(('SUBJECT', 'INTRODUCTION'))
        writer.writerows(lines)

#EX2


data = json.load(open('user_data.json'))
filter = [x for x in data if x['CreditCardType'] == 'American Express']
result = json.dumps(filter)
print(result)

new = pd.DataFrame(eval(result))
new.to_csv('user_data.csv', index=False,header=True)

#EX3


file = pd.read_csv("mushrooms_categorized.csv")
avg = file.groupby('class') 
print(avg.mean())

avg.mean().reset_index().to_json('mushrooms_categorized.json')

#EX4

file = "credit_card.dat"
print("Credit card: \n")

with open(file, 'r') as file:
    for line in file:
        print(''.join([chr(int(line[i:i+6],2)) for i in range(0, len(line), 6)]))

#EX5

from IPython.display import Image
Image("images/data_format.png")
import struct

data = pd.read_csv('data_000637.txt', nrows = 10)
print(data)

file = 'binary_file.dat'
with open(file, 'wb') as binary_file:
    for line in data.values: 
        word = (line[5] << 0 ) 
        word += (line[4] << 5 ) 
        word += (line[3] << 17) 
        word += (line[2] << 49) 
        word += (line[1] << 58)
        word += (line[0] << 62)
        
        binary_file.write(struct.pack('<q', word))

data1 = {}
columns = ['HEAD', 'FPGA', 'CHANNEL', 'ORBIT_CNT', 'BX_CNT', 'TDC_MEAS']
df = pd.DataFrame({}, columns=columns)

with open('binary_file.dat', 'rb') as file:
    file_content = file.read()
    counter = 0
    word_size = 8  
    for i in range(0, len(file_content), word_size):
        counter += 1
        if counter > 10: break
        word = struct.unpack('<q', file_content[i : i + word_size])[0] 
        head     = (word >> 62) & 0x3
        fpga     = (word >> 58) & 0xF
        tdc_chan = (word >> 49) & 0x1FF
        orb_cnt  = (word >> 17) & 0xFFFFFFFF
        bx       = (word >> 5 ) & 0xFFF
        tdc_meas = (word >> 0 ) & 0x1F
        entries = {'HEAD' : head, 'FPGA' : fpga, 'CHANNEL' : tdc_chan, 'ORBIT_CNT' : orb_cnt, 'BX_CNT' : bx, 'TDC_MEAS' : tdc_meas}
        dataframe = df.append(entries, ignore_index=True)
print(dataframe)

import os

path = r'data_000637.txt'
size = os.path.getsize(path)
print(f'{path} SIZE ARE', size, 'BYTES')

path1 = r'binary_file.dat'
size = os.path.getsize(path1)
print(f'{path1} SIZE ARE', size, 'BYTES')
print(f'DIFFERENCES ARE', ((os.path.getsize(path))-(os.path.getsize(path1))), 'BYTES')